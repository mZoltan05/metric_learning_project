{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "# Ensure the following directory structure:\n",
    "# dataset/\n",
    "# ├── class1/\n",
    "# ├── class2/\n",
    "# └── ...\n",
    "\n",
    "\n",
    "dataset_dir = Path(\".\") / \"dataset\"\n",
    "dataset_dir.mkdir(exist_ok=True)\n",
    "\n",
    "classes = [d for d in Path(\"original_images/images\").glob(\"*\") if d.is_dir()]\n",
    "\n",
    "max_sample_count_per_class = None # set to None to copy all samples\n",
    "\n",
    "for _class in classes:\n",
    "    class_name = _class.name\n",
    "    class_dir = dataset_dir / class_name\n",
    "    class_dir.mkdir(exist_ok=True)\n",
    "    for idx, img in enumerate(_class.rglob(\"*.png\")):\n",
    "        if max_sample_count_per_class is not None and idx >= max_sample_count_per_class:\n",
    "            break\n",
    "        parent_name = img.parent.name\n",
    "        shutil.copy(img, class_dir / (parent_name+ \"_\" + img.name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset into train, test and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_dir = Path(\"dataset_split/train\")\n",
    "test_dir = Path(\"dataset_split/test\")\n",
    "val_dir = Path(\"dataset_split/val\")\n",
    "\n",
    "for dir_path in [train_dir, test_dir, val_dir]:\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "train_ratio = 0.6\n",
    "test_ratio = 0.2\n",
    "val_ratio = 0.2\n",
    "\n",
    "for class_dir in dataset_dir.iterdir():\n",
    "    if class_dir.is_dir():\n",
    "        files = list(class_dir.iterdir())\n",
    "        train_files, temp_files = train_test_split(files, test_size=(1 - train_ratio))\n",
    "        val_files, test_files = train_test_split(temp_files, test_size=(test_ratio / (test_ratio + val_ratio)))\n",
    "\n",
    "        (train_dir / class_dir.name).mkdir(parents=True, exist_ok=True)\n",
    "        (test_dir / class_dir.name).mkdir(parents=True, exist_ok=True)\n",
    "        (val_dir / class_dir.name).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        for file in train_files:\n",
    "            shutil.move(str(file), str(train_dir / class_dir.name / file.name))\n",
    "        for file in test_files:\n",
    "            shutil.move(str(file), str(test_dir / class_dir.name / file.name))\n",
    "        for file in val_files:\n",
    "            shutil.move(str(file), str(val_dir / class_dir.name / file.name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepspeech-inference-triton",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
